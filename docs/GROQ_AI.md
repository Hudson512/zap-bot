# Groq AI Integration

## Overview

ZapNode integra com o **Groq** para fornecer respostas autom√°ticas inteligentes via WhatsApp usando modelos de linguagem avan√ßados (LLMs). O sistema mant√©m contexto de conversa√ß√£o e responde automaticamente a mensagens que n√£o s√£o comandos.

## Arquitetura

### Camada de Servi√ßo: `groq.service.js`

**Responsabilidades:**
- Gerenciar cliente Groq SDK
- Manter hist√≥rico de conversa√ß√£o (Map: chatId ‚Üí messages[])
- Gerar respostas com contexto
- Limitar hist√≥rico (√∫ltimas 10 mensagens por padr√£o)

**Padr√£o:** Singleton (inst√¢ncia √∫nica compartilhada)

### Integra√ß√£o com Message Handler

```javascript
// Fluxo de Mensagem
User sends message
  ‚Üí message.handler.js (handle)
  ‚Üí isCommand() check
    ‚îú‚îÄ YES ‚Üí commandRegistry.execute()
    ‚îî‚îÄ NO  ‚Üí handleRegularMessage()
              ‚Üí groqService.generateResponse()
              ‚Üí message.reply(aiResponse)
```

## Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```env
# Groq AI Configuration
GROQ_API_KEY=gsk_your_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_TEMPERATURE=0.7
GROQ_MAX_TOKENS=1024
GROQ_SYSTEM_PROMPT=Voc√™ √© um assistente virtual...

# Features
AI_RESPONSES=true
```

### Modelos Dispon√≠veis

Segundo a documenta√ß√£o do Groq:

1. **llama-3.3-70b-versatile** (Padr√£o)
   - Melhor equil√≠brio entre qualidade e velocidade
   - 128k tokens de contexto
   - Recomendado para uso geral

2. **llama-3.1-8b-instant**
   - Mais r√°pido, menor qualidade
   - 128k tokens de contexto
   - Bom para respostas r√°pidas

3. **mixtral-8x7b-32768**
   - Bom para tarefas complexas
   - 32k tokens de contexto

4. **gemma2-9b-it**
   - Eficiente e leve
   - 8k tokens de contexto

### Par√¢metros de Configura√ß√£o

**GROQ_TEMPERATURE** (0.0 - 2.0)
- `0.0` = Respostas determin√≠sticas e conservadoras
- `0.7` = Balanceado (padr√£o)
- `1.5+` = Mais criativo e variado

**GROQ_MAX_TOKENS**
- M√°ximo de tokens na resposta
- `1024` = ~750 palavras (padr√£o)
- Ajuste conforme necessidade

**GROQ_SYSTEM_PROMPT**
- Define a personalidade e comportamento do bot
- Use para personalizar o tom e estilo de resposta

## Gest√£o de Conversa√ß√£o

### Chat ID Format

```javascript
chatId = `${sessionId}-${contactNumber}@c.us`
// Exemplo: "default-244929782402@c.us"
```

**Importante:** O chat_id combina sess√£o + contato para isolar conversas entre diferentes sess√µes WhatsApp.

### Hist√≥rico de Mensagens

**Estrutura:**
```javascript
conversationHistory.set(chatId, [
  { role: "user", content: "Ol√°!" },
  { role: "assistant", content: "Ol√°! Como posso ajudar?" },
  { role: "user", content: "Me fale sobre..." },
  // ... at√© maxHistoryLength (padr√£o: 10)
]);
```

**Comportamento:**
- Mant√©m √∫ltimas N mensagens (evita limite de tokens)
- Primeira mensagem antiga √© removida quando excede limite
- Hist√≥rico independente por chat_id

### Limpeza de Hist√≥rico

```javascript
// Via comando
!ai clear

// Programaticamente
groqService.clearHistory(chatId);
```

## API do Servi√ßo

### `groqService.initialize()`
Inicializa o cliente Groq. Chamado automaticamente quando WhatsApp est√° pronto.

### `groqService.generateResponse(userMessage, chatId, sessionId)`
```javascript
const response = await groqService.generateResponse(
  "Qual √© a capital de Angola?",
  "default-244929782402@c.us",
  "default"
);
// Returns: "A capital de Angola √© Luanda."
```

### `groqService.clearHistory(chatId)`
```javascript
groqService.clearHistory("default-244929782402@c.us");
// Limpa hist√≥rico desta conversa espec√≠fica
```

### `groqService.isReady()`
```javascript
if (groqService.isReady()) {
  // Servi√ßo inicializado e pronto
}
```

### `groqService.getStats()`
```javascript
const stats = groqService.getStats();
// {
//   initialized: true,
//   activeConversations: 5,
//   maxHistoryLength: 10,
//   model: "llama-3.3-70b-versatile"
// }
```

## Comandos do Bot

### `!ai status`
Mostra status do bot de IA e configura√ß√µes.

**Resposta:**
```
‚úÖ Status do Bot de IA

‚Ä¢ Status: Ativo
‚Ä¢ Modelo: llama-3.3-70b-versatile
‚Ä¢ Temperatura: 0.7
‚Ä¢ Max Tokens: 1024
```

### `!ai stats`
Mostra estat√≠sticas de uso.

**Resposta:**
```
üìä Estat√≠sticas do Bot de IA

‚Ä¢ Inicializado: Sim ‚úÖ
‚Ä¢ Conversas Ativas: 3
‚Ä¢ Hist√≥rico M√°x: 10 mensagens
‚Ä¢ Modelo: llama-3.3-70b-versatile
```

### `!ai clear`
Limpa hist√≥rico de conversa√ß√£o do usu√°rio atual.

**Resposta:**
```
üóëÔ∏è Hist√≥rico de conversa limpo!

O bot de IA n√£o se lembrar√° de mensagens anteriores desta conversa.
```

### `!ai on/off`
Informa sobre como ativar/desativar o bot.

## Fluxo de Inicializa√ß√£o

```javascript
// 1. Server starts
app/server.js

// 2. WhatsApp client initializes
whatsapp.service.js ‚Üí initialize()

// 3. Client ready event
client.on("ready") ‚Üí {
  if (config.features.aiResponses) {
    groqService.initialize() // 4. Groq service starts
  }
}

// 5. Messages are processed
client.on("message") ‚Üí messageHandler.handle()
  ‚Üí handleRegularMessage()
  ‚Üí groqService.generateResponse()
```

## Tratamento de Erros

### Rate Limit
Se limite de requisi√ß√µes for atingido:
```
Desculpe, estou recebendo muitas solicita√ß√µes no momento. 
Por favor, tente novamente em alguns instantes. ‚è≥
```

### API Key Inv√°lida
```
Desculpe, h√° um problema com minha configura√ß√£o. 
Por favor, contate o administrador. üîß
```

### Erro Gen√©rico
```
Desculpe, n√£o consegui processar sua mensagem no momento. 
Por favor, tente novamente. ‚ùå
```

**Logs:** Todos os erros s√£o registrados em `logger.error()` para debugging.

## Rate Limits (Groq)

Segundo a documenta√ß√£o oficial:

**Free Tier:**
- 30 requisi√ß√µes por minuto
- 14,400 tokens por minuto
- ~10-20 mensagens por minuto (dependendo do tamanho)

**Paid Tiers:**
- Limites maiores conforme plano
- Ver: https://console.groq.com/docs/rate-limits

**Estrat√©gia:** O servi√ßo retorna mensagem amig√°vel se limite for atingido.

## Boas Pr√°ticas

### 1. System Prompt Efetivo
```env
GROQ_SYSTEM_PROMPT=Voc√™ √© um atendente de suporte t√©cnico da empresa XYZ. Seja profissional, educado e objetivo. Sempre ofere√ßa ajuda adicional ao final da resposta.
```

### 2. Controle de Hist√≥rico
```javascript
// Aumentar limite para conversas complexas
this.maxHistoryLength = 20; // Padr√£o: 10

// Limpar hist√≥rico ap√≥s inatividade (futura feature)
setTimeout(() => {
  groqService.clearHistory(chatId);
}, 30 * 60 * 1000); // 30 minutos
```

### 3. Desabilitar AI para Comandos
**O sistema j√° faz isso automaticamente:**
```javascript
if (helpers.isCommand(message.body)) {
  // Processa como comando (n√£o envia para IA)
} else {
  // Envia para IA
}
```

### 4. Multi-Session Isolation
Chat IDs incluem sessionId, garantindo que:
- Sess√£o "jpanzo" ‚Üí "jpanzo-244929782402@c.us"
- Sess√£o "default" ‚Üí "default-244929782402@c.us"

**Resultado:** Hist√≥ricos completamente separados!

## Exemplo de Uso

### Conversa Simples
```
User: Ol√°!
Bot: Ol√°! Como posso ajud√°-lo hoje?

User: Me fale sobre Angola
Bot: Angola √© um pa√≠s localizado na costa ocidental da √Åfrica...
```

### Com Contexto
```
User: Qual √© a capital de Angola?
Bot: A capital de Angola √© Luanda.

User: E quantos habitantes tem?
Bot: Luanda tem aproximadamente 8,3 milh√µes de habitantes, sendo a cidade mais populosa do pa√≠s.
```

### Comando vs Mensagem Regular
```
User: !ai status
Bot: [Resposta sobre status do bot]

User: Como voc√™ est√°?
Bot: [IA responde com contexto da conversa]
```

## Troubleshooting

### Bot n√£o responde
1. Verifique `AI_RESPONSES=true` no .env
2. Verifique se `GROQ_API_KEY` est√° correto
3. Veja logs: `logger.error()` mostra detalhes
4. Teste: `!ai status`

### Respostas gen√©ricas/ruins
1. Ajuste `GROQ_TEMPERATURE` (0.7 ‚Üí 1.0 para mais criatividade)
2. Melhore o `GROQ_SYSTEM_PROMPT`
3. Tente modelo diferente (ex: `llama-3.3-70b-versatile`)

### Rate limit atingido
1. Adicione delay entre mensagens
2. Considere upgrade do plano Groq
3. Implemente fila de mensagens (futura feature)

### Hist√≥rico incorreto
1. Use `!ai clear` para resetar
2. Verifique se chat_id est√° correto
3. Reinicie servidor se necess√°rio

## Seguran√ßa

### API Key
- **NUNCA** commite `.env` no Git
- Use `.gitignore` para proteger
- Regenere key se exposta

### System Prompt Injection
O sistema n√£o valida/sanitiza prompts. Para produ√ß√£o:
- Limite caracteres especiais
- Filtre tentativas de manipula√ß√£o
- Use moderation API se dispon√≠vel

### Rate Limiting
- Implemente limiter por usu√°rio (futura feature)
- Monitore uso via `getStats()`

## Roadmap

### Futuras Melhorias
- [ ] Suporte a imagens (via Groq Vision)
- [ ] Fila de mensagens com prioridade
- [ ] Cache de respostas similares
- [ ] Analytics de conversa√ß√£o
- [ ] Auto-limpeza de hist√≥ricos inativos
- [ ] Limiter por usu√°rio (anti-spam)
- [ ] Webhooks para notifica√ß√µes
- [ ] Integra√ß√£o com RAG (Retrieval Augmented Generation)

## Refer√™ncias

- [Groq Documentation](https://console.groq.com/docs/overview)
- [Groq Quickstart](https://console.groq.com/docs/quickstart)
- [Groq Models](https://console.groq.com/docs/models)
- [Groq Rate Limits](https://console.groq.com/docs/rate-limits)
- [Groq SDK (NPM)](https://www.npmjs.com/package/groq-sdk)
